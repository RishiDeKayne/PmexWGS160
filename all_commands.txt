#all commands for Pmex WGS 160 project

#####################################
#####################################
#            DATA
#####################################
#####################################

#PART1 DATA
#raw data: /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#PART2 DATA
#was here:
/hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12
/hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12

#moving files to correct direcory
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/EFR22* /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/MX13* /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/md5sums.txt /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/

rsync -r /hb/groups/kelley_lab/rawdata/tmp/HFWV3DSXC/8023/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#checking files copied completely
cd /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12
grep "MX13" /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/md5sums.txt > ./pmexmd5.txt
md5sum -c pmexmd5.txt

mkdir -p /hb/home/rdekayne/PmexWGS160 && cd /hb/home/rdekayne/PmexWGS160

#####################################
#####################################
#            01_QC - QC on run 1/2
#####################################
#####################################

mkdir -p 01_QC && cd 01_QC

ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/*.fastq.gz > samples.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_05_07\///g' samples.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples.txt
grep -v "_R2_" samples.txt > sample_list.txt
rm samples.txt

wc -l sample_list.txt 
#160 sample_list.txt

## 01_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=Instruction
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/01_QC

cat sample_list.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/01_QC/output_QC/${sample}.done
done

touch all_samples.done

#now to do fastqc and multiqc
module load miniconda3.9
conda create -p /hb/home/rdekayne/envs/multiqc
conda activate /hb/home/rdekayne/envs/multiqc
mamba install multiqc

## 01_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=256x44
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/.

touch all_samples2.done

#####################################
#####################################
#            02_QC - QC on run 2/2
#####################################
#####################################

mkdir -p 02_QC && cd 02_QC

##03_QC
ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/*.fastq.gz > samples2.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_06_12\///g' samples2.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples2.txt
grep -v "_R2_" samples2.txt > sample_list2.txt
rm samples2.txt

wc -l sample_list2.txt 
#160 sample_list2.txt

## 02_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=1-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QCp.out # output file
#SBATCH --error=QCp.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/02_QC

cat sample_list2.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/PmexWGS160/02_QC/output_QC/${sample}.done
done

touch all_samples.done

##run
sbatch 02_QC_part1.sh 

#now to do fastqc and multiqc
module load miniconda3.9
conda activate /hb/home/rdekayne/envs/multiqc

mkdir -p /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/

## 02_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/.

touch all_samples2.done

#run
sbatch 02_QC_part2.sh 


#####################################
#####################################
#            03_QC - QC on post fastp data from run 1 and 2
#####################################
#####################################

mkdir -p 03_QC && cd 03_QC

#run fastqc on post fastp runs

## 03_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC1.out # output file
#SBATCH --error=QC1.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/.

touch all_samples1.done

mv multiqc_report.html multiqc_report_part1.html
mv multiqc_data/ multiqc_data1/

#run
sbatch 03_QC_part1.sh 

## 03_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC2.out # output file
#SBATCH --error=QC2.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/.

touch all_samples2.done

#run
sbatch 03_QC_part2.sh 

mv multiqc_report.html multiqc_report_part2.html
mv multiqc_data/ multiqc_data2/

#####################################
#####################################
#            04_mapping 
#####################################
#####################################
mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping && cd /hb/home/rdekayne/PmexWGS160/04_mapping

#now ready for mapping for fastq files in /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed and /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2

#want to first try with S Pmex assembly:
cp /hb/groups/kelley_lab/poeciliids/hifi_genomes/04_structural_functional_annotation/01_annotate_repeats/02_Repeatmasker/m84066_230420_220836_s1.hifi_reads.bc1020.asm.bp.p_ctg.softmasked.fa /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa

#index assembly
module load samtools
samtools faidx Pmex_S_ref.fa 
module load bwa
bwa index Pmex_S_ref.fa

#and use samples in /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt

#make scratch directory for sam/bam writing
/hb/scratch/rdekayne/mapping/

# 04.1_PmexWGS160_mapping.sh

#!/bin/bash
#SBATCH --job-name=mapping
#SBATCH --time=0-24:00:00
#SBATCH --partition=256x44
#SBATCH --output=mapping.%j.out # output file
#SBATCH --error=mapping.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=24
#SBATCH --mem=16GB 

module load bwa-mem2/2.2.1 sambamba

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

#PART1
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping1.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping2.done

#PART2
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping3.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping4.done


##submit
sbatch --array=1 04.1_PmexWGS160_mapping.sh

sbatch --array=2-160%12 04.1_PmexWGS160_mapping.sh

mkdir /hb/home/rdekayne/PmexWGS160/04_mapping/bams
mkdir /hb/scratch/rdekayne/mapping/tmp_bam

# 04.2_PmexWGS160_processing.sh

#!/bin/bash
#SBATCH --job-name=mapping_processing
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=processing.%j.out # output file
#SBATCH --error=processing.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=24
#SBATCH --mem=40GB 

module load bwa-mem2/2.2.1 sambamba picard

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

#PART1
picard FixMateInformation I=/hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.bam VALIDATION_STRINGENCY=LENIENT OUTPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.raw.bam

sambamba sort /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.raw.bam -o /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.sorted.raw.bam -t 24 -m 50GB

picard MarkDuplicates INPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.sorted.raw.bam OUTPUT=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam METRICS_FILE=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.txt VALIDATION_STRINGENCY=LENIENT MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1024

sambamba index /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam

#PART2
picard FixMateInformation I=/hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.bam VALIDATION_STRINGENCY=LENIENT OUTPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.raw.bam

sambamba sort /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.raw.bam -o /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.sorted.raw.bam -t 24 -m 50GB

picard MarkDuplicates INPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.sorted.raw.bam OUTPUT=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam METRICS_FILE=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.txt VALIDATION_STRINGENCY=LENIENT MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1024

sambamba index /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam

#now remove all intermediate files
rm /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}.*

touch ${indiv_name}.processing.done

##submit
sbatch --array=1-160 04.2_PmexWGS160_processing.sh


mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping/mosdepth && cd /hb/home/rdekayne/PmexWGS160/04_mapping/mosdepth

mkdir /hb/scratch/rdekayne/mapping/combined_bams

# 04.3_PmexWGS160_combine_coverage.sh

#!/bin/bash
#SBATCH --job-name=mosdepth
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=depth.%j.out # output file
#SBATCH --error=depth.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load samtools sambamba picard mosdepth

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

samtools merge -o /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam 

sambamba index /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam 

mosdepth -n ${indiv_name}_combined.sorted.dup.PmexS.bam /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam && touch ${indiv_name}.mosdepth.done 

##run
sbatch --array=1-160 04.3_PmexWGS160_combine_coverage.sh

ls *.mosdepth.summary.txt > files.txt
grep 'total' *.mosdepth.summary.txt | cut -f4 >> bam_raw_coverage.txt > coverage.txt
paste files.txt coverage.txt > coverage_160.txt
rm files.txt coverage.txt

#now run flatstat
mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping/flagstat_output && cd /hb/home/rdekayne/PmexWGS160/04_mapping/flagstat_output

## 04.4_PmexWGS160_flagstat.sh

#!/bin/bash
#SBATCH --job-name=mosdepth
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=depth.%j.out # output file
#SBATCH --error=depth.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load samtools sambamba picard mosdepth

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

samtools flagstat /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam && touch ${indiv_name}_combined.sorted.dup.PmexS.bam.done

##run
sbatch --array=1-160%20 04.4_PmexWGS160_flagstat.sh

#now replace bam files in home dir with those combined and in scratch
cd /hb/home/rdekayne/PmexWGS160/04_mapping/bams/
rm /hb/home/rdekayne/PmexWGS160/04_mapping/bams/MX*
cp /hb/scratch/rdekayne/mapping/combined_bams/* .

#####################################
#####################################
#            05_genotyping 
#####################################
#####################################

#make genotyping directory
mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/ && cd /hb/home/rdekayne/PmexWGS160/05_genotyping/
#and make a directory for the done-files
mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/done_files
#and make directory for raw vcf files
mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_vcfs

#prepare reference scaffold list
ls /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa

#want to get scaffolds in ascending order:
sort -k 2rn /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa.fai cut -f1 > /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list

#make bam list too
ls /hb/scratch/rdekayne/mapping/combined_bams/*.bam > bam.list

## 05.1_PmexWGS160_genotyping.sh

#!/bin/bash
#SBATCH --job-name=genotype
#SBATCH --time=0-12:00:00
#SBATCH --partition=128x24
#SBATCH --output=geno.%j.out # output file
#SBATCH --error=geno.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load htslib/1.17 sambamba picard mosdepth samtools bcftools

numb=${SLURM_ARRAY_TASK_ID}
scaf_name=$(cat /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list | sed -n ${numb}p)

bcftools mpileup -O u -d 250 --skip-indels -f /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa --annotate FORMAT/DP --bam-list /hb/home/rdekayne/PmexWGS160/05_genotyping/bam.list -r "${scaf_name}" | bcftools call -m -f GQ -O v | bgzip > /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_vcfs/"${scaf_name}".raw.vcf.gz && touch /hb/home/rdekayne/PmexWGS160/05_genotyping/done_files/"${scaf_name}".raw.vcf.gz.done

#run
sbatch --array=1-115%16 05.1_PmexWGS160_genotyping.sh

bcftools query -l ptg000001l.raw.vcf.gz > old_names.txt
sed 's/\/hb\/scratch\/rdekayne\/mapping\/combined_bams\///g' old_names.txt > new_names.txt
sed -i 's/_L004_combined.sorted.dup.PmexS.bam//g' new_names.txt
cut -d '_' -f 1 new_names.txt > final_names.txt

paste old_names.txt final_names.txt > reheader.txt

mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_reheader_vcfs

## 05.2_PmexWGS160_genotype_rename_filt.sh

#!/bin/bash
#SBATCH --job-name=genotype
#SBATCH --time=0-24:00:00
#SBATCH --partition=128x24
#SBATCH --output=geno.%j.out # output file
#SBATCH --error=geno.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=30GB 

module load htslib/1.17 sambamba picard mosdepth samtools bcftools

numb=${SLURM_ARRAY_TASK_ID}
scaf_name=$(cat /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list | sed -n ${numb}p)

bcftools reheader --samples /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_vcfs/reheader.txt -o /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_reheader_vcfs/"${scaf_name}".reheader.raw.vcf.gz /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_vcfs/"${scaf_name}".raw.vcf.gz && touch /hb/home/rdekayne/PmexWGS160/05_genotyping/done_files/"${scaf_name}".done

#run
sbatch --array=1-115%16 05.2_PmexWGS160_genotype_rename_filt.sh

## 05.3_PmexWGS160_index.sh 

#!/bin/bash
#SBATCH --job-name=genotype
#SBATCH --time=0-24:00:00
#SBATCH --partition=128x24
#SBATCH --output=geno.%j.out # output file
#SBATCH --error=geno.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load htslib/1.17 sambamba picard mosdepth samtools bcftools

numb=${SLURM_ARRAY_TASK_ID}
scaf_name=$(cat /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list | sed -n ${numb}p)

bcftools index /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_reheader_vcfs/"${scaf_name}".reheader.raw.vcf.gz

##run
sbatch --array=1-115 05.3_PmexWGS160_index.sh 


## 05.4_PmexWGS160_genotype_filt.sh 

#!/bin/bash
#SBATCH --job-name=genotype
#SBATCH --time=0-24:00:00
#SBATCH --partition=128x24
#SBATCH --output=geno.%j.out # output file
#SBATCH --error=geno.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=30GB 

module load htslib/1.17 sambamba picard mosdepth samtools bcftools

numb=${SLURM_ARRAY_TASK_ID}
scaf_name=$(cat /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list | sed -n ${numb}p)

mkdir -p /hb/scratch/rdekayne/genotype_temp_"${scaf_name}"

bcftools filter -Ou /hb/home/rdekayne/PmexWGS160/05_genotyping/raw_reheader_vcfs/"${scaf_name}".reheader.raw.vcf.gz -e 'FORMAT/DP < 7 | FORMAT/GQ < 30' --set-GTs . -e 'AN < 2' | bcftools sort -Oz --temp-dir /hb/scratch/rdekayne/genotype_temp_"${scaf_name}" -o /hb/home/rdekayne/PmexWGS160/05_genotyping/filt_vcfs/"${scaf_name}"_filt_mindepth7_minqual30.vcf.gz && touch /hb/home/rdekayne/PmexWGS160/05_genotyping/filt_vcfs/"${scaf_name}"_filt.done

##run
sbatch --array=1-115%16 05.4_PmexWGS160_genotype_filt.sh


## 05.5_PmexWGS160_concat_and_filt.sh

#!/bin/bash
#SBATCH --job-name=filt
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=geno_filt.%j.out # output file
#SBATCH --error=geno_filt.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=60GB 

module load htslib/1.17 sambamba picard mosdepth samtools bcftools

mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs
mkdir -p /hb/scratch/rdekayne/genotype_temp_concat
mkdir -p /hb/scratch/rdekayne/genotype_temp_concat_filt

ls /hb/home/rdekayne/PmexWGS160/05_genotyping/filt_vcfs/*_filt_mindepth7_minqual30.vcf.gz > vcf_to_merge.txt

bcftools concat -Ou -f vcf_to_merge.txt | bcftools sort -Oz --temp-dir /hb/scratch/rdekayne/genotype_temp_concat -o /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30.vcf.gz

#no missing filter for SNPs
bcftools filter -Oz /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30.vcf.gz -e 'INFO/MAC < 1 | AN < 320' | bcftools view -m2 -M2 -v snps | bcftools sort -Oz --temp-dir /hb/scratch/rdekayne/genotype_temp_concat_filt -o /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz

bcftools view -H /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz | wc -l

touch genotype_stats.done

##run
sbatch 05.5_PmexWGS160_concat_and_filt.sh

#####################################
#####################################
#            06_PCA
#####################################
#####################################

mkdir -p /hb/home/rdekayne/PmexWGS160/06_PCA && cd /hb/home/rdekayne/PmexWGS160/06_PCA

#06.1_PCA_unfilt.sh

#!/bin/bash
#SBATCH --job-name=pca
#SBATCH --time=0-12:00:00
#SBATCH --partition=128x24
#SBATCH --output=pca.%j.out # output file
#SBATCH --error=pca.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load plink

cd /hb/home/rdekayne/PmexWGS160/06_PCA

plink --vcf /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz --double-id --allow-extra-chr --set-missing-var-ids @:# --make-bed --pca --out 160_unfilt_out

touch /hb/home/rdekayne/PmexWGS160/06_PCA/160_pca.done

##run
sbatch 06.1_PCA_unfilt.sh

#5494680 variants and 160 people pass filters and QC.

#####################################
#####################################
#            07_LD
#####################################
#####################################

mkdir -p /hb/home/rdekayne/PmexWGS160/07_LD && cd /hb/home/rdekayne/PmexWGS160/07_LD

#07.1_LD.sh

#!/bin/bash
#SBATCH --job-name=LD
#SBATCH --time=0-12:00:00
#SBATCH --partition=128x24
#SBATCH --output=pca.%j.out # output file
#SBATCH --error=pca.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load plink bcftools

cd /hb/home/rdekayne/PmexWGS160/07_LD

#mkdir -p /hb/scratch/rdekayne/bcf_LD

#bcftools index /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz

#bcftools view /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz --regions ptg000001l | bcftools sort -Oz --temp-dir /hb/scratch/rdekayne/bcf_LD -o /hb/home/rdekayne/PmexWGS160/07_LD/ptg000001l_mindepth7_minqual30_mac1_AN320.vcf.gz

plink --vcf /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz --double-id --allow-extra-chr \
--set-missing-var-ids @:# \
--maf 0.01 --geno 0.1 --mind 0.5 --chr ptg000001l \
--thin 0.1 -r2 gz --ld-window 100 --ld-window-kb 1000 \
--ld-window-r2 0 \
--make-bed --out 160_LD_out

touch /hb/home/rdekayne/PmexWGS160/07_LD/LD_pca.done

##run
sbatch 07.1_LD.sh

#23330 variants and 160 people pass filters and QC.

module load miniconda3
conda create -n py27 python=2.7 ipykernel
conda activate py27

# run mark python script
python ./ld_decay_calc.py -i 160_LD_out.ld.gz -o 160_LD_chr1


#07.2_LD.sh

#!/bin/bash
#SBATCH --job-name=LD
#SBATCH --time=0-12:00:00
#SBATCH --partition=128x24
#SBATCH --output=pca.%j.out # output file
#SBATCH --error=pca.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load plink bcftools

plink --vcf /hb/home/rdekayne/PmexWGS160/05_genotyping/concat_vcfs/PmexWGS160_mindepth7_minqual30_mac1_AN320.vcf.gz --double-id --allow-extra-chr --set-missing-var-ids @:# --r2 inter-chr gz dprime yes-really --ld-window-r2 0 --chr ptg000001l --thin 0.1 --make-bed --out 160_LD_out2

##run
sbatch 07.2_LD.sh

#####################################
#####################################
#            NCBI UPLOAD
#####################################
#####################################

##rename_files_part1.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_05_07_renamed/"${file/001.fastq.gz/001_part1.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part1.sh

###rename_files_part2.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_06_12_renamed/"${file/001.fastq.gz/001_part2.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part2.sh
