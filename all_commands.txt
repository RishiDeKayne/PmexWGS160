#all commands for Pmex WGS 160 project

#####################################
#####################################
#            DATA
#####################################
#####################################

#PART1 DATA
#raw data: /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#PART2 DATA
#was here:
/hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12
/hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12

#moving files to correct direcory
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/EFR22* /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/MX13* /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/md5sums.txt /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/

rsync -r /hb/groups/kelley_lab/rawdata/tmp/HFWV3DSXC/8023/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#checking files copied completely
cd /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12
grep "MX13" /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/md5sums.txt > ./pmexmd5.txt
md5sum -c pmexmd5.txt

mkdir -p /hb/home/rdekayne/PmexWGS160 && cd /hb/home/rdekayne/PmexWGS160

#####################################
#####################################
#            01_QC - QC on run 1/2
#####################################
#####################################

mkdir -p 01_QC && cd 01_QC

ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/*.fastq.gz > samples.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_05_07\///g' samples.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples.txt
grep -v "_R2_" samples.txt > sample_list.txt
rm samples.txt

wc -l sample_list.txt 
#160 sample_list.txt

## 01_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=Instruction
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/01_QC

cat sample_list.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/01_QC/output_QC/${sample}.done
done

touch all_samples.done

#now to do fastqc and multiqc
module load miniconda3.9
conda create -p /hb/home/rdekayne/envs/multiqc
conda activate /hb/home/rdekayne/envs/multiqc
mamba install multiqc

## 01_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=256x44
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/.

touch all_samples2.done

#####################################
#####################################
#            02_QC - QC on run 2/2
#####################################
#####################################

mkdir -p 02_QC && cd 02_QC

##03_QC
ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/*.fastq.gz > samples2.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_06_12\///g' samples2.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples2.txt
grep -v "_R2_" samples2.txt > sample_list2.txt
rm samples2.txt

wc -l sample_list2.txt 
#160 sample_list2.txt

## 02_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=1-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QCp.out # output file
#SBATCH --error=QCp.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/02_QC

cat sample_list2.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/PmexWGS160/02_QC/output_QC/${sample}.done
done

touch all_samples.done

##run
sbatch 02_QC_part1.sh 

#now to do fastqc and multiqc
module load miniconda3.9
conda activate /hb/home/rdekayne/envs/multiqc

mkdir -p /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/

## 02_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/.

touch all_samples2.done

#run
sbatch 02_QC_part2.sh 


#####################################
#####################################
#            03_QC - QC on post fastp data from run 1 and 2
#####################################
#####################################

mkdir -p 03_QC && cd 03_QC

#run fastqc on post fastp runs

## 03_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC1.out # output file
#SBATCH --error=QC1.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/.

touch all_samples1.done

mv multiqc_report.html multiqc_report_part1.html
mv multiqc_data/ multiqc_data1/

#run
sbatch 03_QC_part1.sh 

## 03_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC2.out # output file
#SBATCH --error=QC2.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/.

touch all_samples2.done

#run
sbatch 03_QC_part2.sh 

mv multiqc_report.html multiqc_report_part2.html
mv multiqc_data/ multiqc_data2/

#####################################
#####################################
#            04_mapping - QC on post fastp data from run 1 and 2
#####################################
#####################################
mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping && cd /hb/home/rdekayne/PmexWGS160/04_mapping

#now ready for mapping for fastq files in /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed and /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2

#want to first try with S Pmex assembly:
cp /hb/groups/kelley_lab/poeciliids/hifi_genomes/04_structural_functional_annotation/01_annotate_repeats/02_Repeatmasker/m84066_230420_220836_s1.hifi_reads.bc1020.asm.bp.p_ctg.softmasked.fa /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa

#index assembly
module load samtools
samtools faidx Pmex_S_ref.fa 
module load bwa
bwa index Pmex_S_ref.fa

#and use samples in /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt

#make scratch directory for sam/bam writing
/hb/scratch/rdekayne/mapping/

# 04.1_PmexWGS160_mapping.sh

#!/bin/bash
#SBATCH --job-name=mapping
#SBATCH --time=0-24:00:00
#SBATCH --partition=256x44
#SBATCH --output=mapping.%j.out # output file
#SBATCH --error=mapping.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=24
#SBATCH --mem=16GB 

module load bwa-mem2/2.2.1 sambamba

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

#PART1
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping1.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping2.done

#PART2
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping3.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping4.done


##submit
sbatch --array=1 04.1_PmexWGS160_mapping.sh









#####################################
#####################################
#            NCBI UPLOAD
#####################################
#####################################

##rename_files_part1.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_05_07_renamed/"${file/001.fastq.gz/001_part1.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part1.sh

###rename_files_part2.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_06_12_renamed/"${file/001.fastq.gz/001_part2.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part2.sh
