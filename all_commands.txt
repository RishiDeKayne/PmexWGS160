#all commands for Pmex WGS 160 project

#####################################
#####################################
#            DATA
#####################################
#####################################

#PART1 DATA
#raw data: /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#PART2 DATA
#was here:
/hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12
/hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12

#moving files to correct direcory
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/EFR22* /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/gambusia_resequencing_2024_06_12/
rsync /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/MX13* /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/
rsync -r /hb/groups/kelley_lab/rawdata/tmp/HJCW7DSXC/8226/md5sums.txt /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/

rsync -r /hb/groups/kelley_lab/rawdata/tmp/HFWV3DSXC/8023/INFO /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07

#checking files copied completely
cd /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12
grep "MX13" /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/md5sums.txt > ./pmexmd5.txt
md5sum -c pmexmd5.txt

mkdir -p /hb/home/rdekayne/PmexWGS160 && cd /hb/home/rdekayne/PmexWGS160

#####################################
#####################################
#            01_QC - QC on run 1/2
#####################################
#####################################

mkdir -p 01_QC && cd 01_QC

ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/*.fastq.gz > samples.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_05_07\///g' samples.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples.txt
grep -v "_R2_" samples.txt > sample_list.txt
rm samples.txt

wc -l sample_list.txt 
#160 sample_list.txt

## 01_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=Instruction
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/01_QC

cat sample_list.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/01_QC/output_QC/${sample}.done
done

touch all_samples.done

#now to do fastqc and multiqc
module load miniconda3.9
conda create -p /hb/home/rdekayne/envs/multiqc
conda activate /hb/home/rdekayne/envs/multiqc
mamba install multiqc

## 01_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-12:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=256x44
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_05_07/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/.

touch all_samples2.done

#####################################
#####################################
#            02_QC - QC on run 2/2
#####################################
#####################################

mkdir -p 02_QC && cd 02_QC

##03_QC
ls /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/*.fastq.gz > samples2.txt
sed -i 's/\/hb\/groups\/kelley_lab\/rawdata\/poeciliid\/pmex_resequencing_2024_06_12\///g' samples2.txt
sed -i 's/_R1_001\.fastq\.gz//g' samples2.txt
grep -v "_R2_" samples2.txt > sample_list2.txt
rm samples2.txt

wc -l sample_list2.txt 
#160 sample_list2.txt

## 02_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=fastp
#SBATCH --time=1-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QCp.out # output file
#SBATCH --error=QCp.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu fastp

cd /hb/home/rdekayne/PmexWGS160/02_QC

cat sample_list2.txt | while read sample
do
fastp -i /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz -I /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz -o /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz -O /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz -h ${sample}.html && touch /hb/home/rdekayne/PmexWGS160/02_QC/output_QC/${sample}.done
done

touch all_samples.done

##run
sbatch 02_QC_part1.sh 

#now to do fastqc and multiqc
module load miniconda3.9
conda activate /hb/home/rdekayne/envs/multiqc

mkdir -p /hb/home/rdekayne/PmexWGS160/01_QC/fastqc_reports/

## 02_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC.out # output file
#SBATCH --error=QC.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R1_001.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/ --noextract /hb/groups/kelley_lab/rawdata/poeciliid/pmex_resequencing_2024_06_12/${sample}_R2_001.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/02_QC/fastqc_reports/.

touch all_samples2.done

#run
sbatch 02_QC_part2.sh 


#####################################
#####################################
#            03_QC - QC on post fastp data from run 1 and 2
#####################################
#####################################

mkdir -p 03_QC && cd 03_QC

#run fastqc on post fastp runs

## 03_QC_part1.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC1.out # output file
#SBATCH --error=QC1.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports1/.

touch all_samples1.done

mv multiqc_report.html multiqc_report_part1.html
mv multiqc_data/ multiqc_data1/

#run
sbatch 03_QC_part1.sh 

## 03_QC_part2.sh 

#!/bin/bash
#SBATCH --job-name=multiqc
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=QC2.out # output file
#SBATCH --error=QC2.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=2 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

cat ../02_QC/sample_list2.txt | while read sample
do
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R1.out.fastq.gz
fastqc -t 1 -o /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/ --noextract /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${sample}_R2.out.fastq.gz
done

multiqc /hb/home/rdekayne/PmexWGS160/03_QC/fastqc_reports2/.

touch all_samples2.done

#run
sbatch 03_QC_part2.sh 

mv multiqc_report.html multiqc_report_part2.html
mv multiqc_data/ multiqc_data2/

#####################################
#####################################
#            04_mapping 
#####################################
#####################################
mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping && cd /hb/home/rdekayne/PmexWGS160/04_mapping

#now ready for mapping for fastq files in /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed and /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2

#want to first try with S Pmex assembly:
cp /hb/groups/kelley_lab/poeciliids/hifi_genomes/04_structural_functional_annotation/01_annotate_repeats/02_Repeatmasker/m84066_230420_220836_s1.hifi_reads.bc1020.asm.bp.p_ctg.softmasked.fa /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa

#index assembly
module load samtools
samtools faidx Pmex_S_ref.fa 
module load bwa
bwa index Pmex_S_ref.fa

#and use samples in /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt

#make scratch directory for sam/bam writing
/hb/scratch/rdekayne/mapping/

# 04.1_PmexWGS160_mapping.sh

#!/bin/bash
#SBATCH --job-name=mapping
#SBATCH --time=0-24:00:00
#SBATCH --partition=256x44
#SBATCH --output=mapping.%j.out # output file
#SBATCH --error=mapping.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=24
#SBATCH --mem=16GB 

module load bwa-mem2/2.2.1 sambamba

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

#PART1
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping1.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.sam && touch ${indiv_name}.mapping2.done

#PART2
# call bwa
/hb/software/apps/bwa-mem2/gnu-2.2.1/bin/bwa-mem2 mem -t 24 /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R1.out.fastq.gz /hb/groups/kelley_lab/Rishi/PmexWGS160/data/fastp_processed2/${indiv_name}_R2.out.fastq.gz > /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping3.done

#run sambamba
sambamba view -S /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam -f bam -o /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.bam -t 24 -l 9 && rm /hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.sam && touch ${indiv_name}.mapping4.done


##submit
sbatch --array=1 04.1_PmexWGS160_mapping.sh

sbatch --array=2-160%12 04.1_PmexWGS160_mapping.sh

mkdir /hb/home/rdekayne/PmexWGS160/04_mapping/bams
mkdir /hb/scratch/rdekayne/mapping/tmp_bam

# 04.2_PmexWGS160_processing.sh

#!/bin/bash
#SBATCH --job-name=mapping_processing
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=processing.%j.out # output file
#SBATCH --error=processing.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=24
#SBATCH --mem=40GB 

module load bwa-mem2/2.2.1 sambamba picard

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

#PART1
picard FixMateInformation I=/hb/scratch/rdekayne/mapping/output.${indiv_name}_part1.raw.bam VALIDATION_STRINGENCY=LENIENT OUTPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.raw.bam

sambamba sort /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.raw.bam -o /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.sorted.raw.bam -t 24 -m 50GB

picard MarkDuplicates INPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part1.sorted.raw.bam OUTPUT=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam METRICS_FILE=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.txt VALIDATION_STRINGENCY=LENIENT MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1024

sambamba index /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam

#PART2
picard FixMateInformation I=/hb/scratch/rdekayne/mapping/output.${indiv_name}_part2.raw.bam VALIDATION_STRINGENCY=LENIENT OUTPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.raw.bam

sambamba sort /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.raw.bam -o /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.sorted.raw.bam -t 24 -m 50GB

picard MarkDuplicates INPUT=/hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}_part2.sorted.raw.bam OUTPUT=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam METRICS_FILE=/hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.txt VALIDATION_STRINGENCY=LENIENT MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1024

sambamba index /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam

#now remove all intermediate files
rm /hb/scratch/rdekayne/mapping/tmp_bam/${indiv_name}.*

touch ${indiv_name}.processing.done

##submit
sbatch --array=1-160 04.2_PmexWGS160_processing.sh


mkdir -p /hb/home/rdekayne/PmexWGS160/04_mapping/mosdepth && cd /hb/home/rdekayne/PmexWGS160/04_mapping/mosdepth

mkdir /hb/scratch/rdekayne/mapping/combined_bams

# 04.3_PmexWGS160_combine_coverage.sh

#!/bin/bash
#SBATCH --job-name=mosdepth
#SBATCH --time=0-12:00:00
#SBATCH --partition=256x44
#SBATCH --output=depth.%j.out # output file
#SBATCH --error=depth.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load samtools sambamba picard mosdepth

ind=${SLURM_ARRAY_TASK_ID}
indiv_name=$(cat /hb/home/rdekayne/PmexWGS160/02_QC/sample_list2.txt | sed -n ${ind}p)

samtools merge -o /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part1.sorted.dup.PmexS.bam /hb/home/rdekayne/PmexWGS160/04_mapping/bams/${indiv_name}_part2.sorted.dup.PmexS.bam 

sambamba index /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam 

mosdepth -n ${indiv_name}_combined.sorted.dup.PmexS.bam /hb/scratch/rdekayne/mapping/combined_bams/${indiv_name}_combined.sorted.dup.PmexS.bam && touch ${indiv_name}.mosdepth.done 

##run
sbatch --array=1-160 04.3_PmexWGS160_combine_coverage.sh

module load mosdepth
#now make html file
python ./plot-dist.py ./*global.dist.txt

ls *.mosdepth.summary.txt > files.txt
grep 'total' *.mosdepth.summary.txt | cut -f4 >> bam_raw_coverage.txt > coverage.txt
paste files.txt coverage.txt > coverage_24.txt
rm files.txt coverage.txt

#####################################
#####################################
#            05_genotyping 
#####################################
#####################################

#make genotyping directory
mkdir -p /hb/home/rdekayne/PmexWGS160/05_genotyping/ && cd /hb/home/rdekayne/PmexWGS160/05_genotyping/
#and make a directory for the done-files
mkdir /hb/home/rdekayne/05_genotyping/done_files

#prepare reference scaffold list
ls /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa

#want to get scaffolds in ascending order:
sort -k 2rn /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa.fai cut -f1 > /hb/home/rdekayne/PmexWGS160/04_mapping/scaf.list

#make bam list too
ls /hb/groups/kelley_lab/Rishi/processed_bams/*.bam > bam.list

## 05.1_PmexWGS160_genotyping.sh

#!/bin/bash
#SBATCH --job-name=genotype
#SBATCH --time=0-12:00:00
#SBATCH --partition=128x24
#SBATCH --output=geno.%j.out # output file
#SBATCH --error=geno.%j.err # error file
#SBATCH -N 1
#SBATCH --cpus-per-task=1
#SBATCH --mem=10GB 

module load sambamba picard mosdepth samtools bcftools

numb=${SLURM_ARRAY_TASK_ID}
scaf_name=$(cat /hb/home/rdekayne/04_H2S_genotyping/scaf.list | sed -n ${numb}p)

bcftools mpileup -O u -d 250 --skip-indels -f /hb/home/rdekayne/PmexWGS160/04_mapping/Pmex_S_ref.fa --annotate FORMAT/DP --bam-list /hb/home/rdekayne/04_H2S_genotyping/bam.list -r "${scaf_name}" | bcftools call -m -f GQ -O v | bgzip > /hb/home/rdekayne/04_H2S_genotyping/"${scaf_name}".raw.vcf.gz && touch /hb/home/rdekayne/04_H2S_genotyping/done_files/"${scaf_name}".raw.vcf.gz.done

#run
sbatch --array=1-25 04.1_H2S_genotyping.sh









#####################################
#####################################
#            NCBI UPLOAD
#####################################
#####################################

##rename_files_part1.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_05_07_renamed/"${file/001.fastq.gz/001_part1.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part1.sh

###rename_files_part2.sh

#!/bin/bash
#SBATCH --job-name=rename
#SBATCH --time=0-24:00:00 # Wall clock time limit in Days-Hours:min:seconds
#SBATCH --partition=128x24
#SBATCH --output=rename.out # output file
#SBATCH --error=rename.err # error file
#SBATCH --ntasks=1 # Run 1 job
#SBATCH --ntasks-per-node=1 # One task per computer
#SBATCH --cpus-per-task=1 # 2 CPUs per job
#SBATCH --mem=4GB # Memory limit of 4GB

module load hb hb-gnu

for file in *.fastq.gz; do cp "$file" ../pmex_resequencing_2024_06_12_renamed/"${file/001.fastq.gz/001_part2.fastq.gz}"; done

touch all.done.txt

##run
sbatch rename_files_part2.sh
